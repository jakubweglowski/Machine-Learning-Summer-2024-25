{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e38711ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Binary cross-entropy loss function\n",
    "\n",
    "The binary cross-entropy function, which will be used throughout the analysis, is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ab1ef0",
   "metadata": {},
   "source": [
    "$$\n",
    "L(y, z) = -y \\log(\\sigma(z)) - (1 - y) \\log(1 - \\sigma(z)),\n",
    "$$\n",
    "where $\\sigma(z) = \\frac{1}{1+e^{-z}}$ is called a *sigmoid* function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffcf1d",
   "metadata": {},
   "source": [
    "We will usually treat this function as a function of $z$ having $y$ as parameter:\n",
    "$$\n",
    "L(y, z) = g_y(z)\n",
    "$$\n",
    "\n",
    "We start off by calculating derivative of $g$:\n",
    "$$\n",
    "g_y'(z) = \\frac{\\partial}{\\partial z}{L(y, z)} = -y\\frac{\\sigma'(z)}{\\sigma(z)} - (1-y)\\frac{-\\sigma'(z)}{1-\\sigma(z)} = -y\\frac{\\sigma'(z)}{\\sigma(z)} + (1-y)\\frac{\\sigma'(z)}{1-\\sigma(z)}\n",
    "$$\n",
    "We have:\n",
    "$$\\frac{\\sigma'(z)}{\\sigma(z)} = \\frac{-\\frac{-e^{-z}}{(1+e^{-z})^2}}{\\frac{1}{1+e^{-z}}} = \\frac{e^{-z}}{1+e^{-z}} = \\frac{1}{1+e^z} = \\sigma(-z)\n",
    "$$\n",
    "and also:\n",
    "$$\\frac{\\sigma'(z)}{1-\\sigma(z)} = \\frac{-\\frac{-e^{-z}}{(1+e^{-z})^2}}{1-\\frac{1}{1+e^{-z}}} = \\frac{\\frac{e^{-z}}{(1+e^{-z})^2}}{\\frac{e^{-z}}{1+e^{-z}}} = \\frac{1}{1+e^{-z}} = \\sigma(z)$$\n",
    "Therefore we obtain the following result:\n",
    "$$\n",
    "g_y'(z) = \\frac{\\partial}{\\partial z}{L(y, z)} = -y\\frac{\\sigma'(z)}{\\sigma(z)} - (1-y)\\frac{-\\sigma'(z)}{1-\\sigma(z)} = -y\\sigma(-z) + (1-y)\\sigma(z) = \\sigma(z) - y(\\sigma(z) + \\sigma(-z))\n",
    "$$\n",
    "Our aim is to find:\n",
    "$$\n",
    "\\lambda^* = \\arg\\min_{\\lambda} \\sum_{i=1}^{n} L(y_i, \\lambda).\n",
    "$$\n",
    "Keeping in mind that $\\sum_{i=1}^{n}{y_i} = m$, we can write:\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\lambda}\\sum_{i=1}^{n} L(y_i, \\lambda) = \\sum_{i=1}^{n}{g_{y_i}'(\\lambda)} = \\sum_{i=1}^{n}{\\left(\\sigma(\\lambda) - y_i(\\sigma(\\lambda) + \\sigma(-\\lambda))\\right)} = n\\sigma(\\lambda) + m(\\sigma(\\lambda) + \\sigma(-\\lambda)) = k\\sigma(\\lambda) - m\\sigma(-\\lambda)\n",
    "$$\n",
    "We therefore have to find $\\lambda^*$ such that:\n",
    "$$k\\sigma(\\lambda^*) - m\\sigma(-\\lambda^*) = 0$$\n",
    "$$k\\sigma(\\lambda^*) = m\\sigma(-\\lambda^*)$$\n",
    "$$\\frac{\\sigma(\\lambda^*)}{\\sigma(-\\lambda^*)} = \\frac{m}{k}$$\n",
    "$$\\frac{\\frac{1}{1 + e^{-\\lambda^*}}}{\\frac{1}{1 + e^{\\lambda^*}}} = \\frac{m}{k}$$\n",
    "$$\\frac{1 + e^{\\lambda^*}}{1 + e^{-\\lambda^*}} = \\frac{m}{k}$$\n",
    "$$\\frac{e^{\\lambda^*} + e^{2\\lambda^*}}{1 + e^{\\lambda^*}} = \\frac{m}{k}$$\n",
    "Setting $u = e^{\\lambda^*}$, we obtain a quadratic equation:\n",
    "$$u^2 + u\\left(1-\\frac{m}{k}\\right) - \\frac{m}{k} = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import newton\n",
    "\n",
    "def sigma(z: np.ndarray) -> np.ndarray:\n",
    "    return 1./(1.+np.exp(-z))\n",
    "\n",
    "def L(z: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    return -y * np.log(sigma(z)) - (1. - y) * np.log(1. - sigma(z))\n",
    "\n",
    "def L_prime(z: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    return sigma(z) - y * (sigma(z) + sigma(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f719043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"1\": 108, number of \"0\": 892, total number of labels: 1000.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "n = 1000 # number of 0-1 labels\n",
    "y = np.random.binomial(1, 0.1, n)\n",
    "m = np.sum(y)\n",
    "k = n - m\n",
    "print(f'Number of \"1\": {m}, number of \"0\": {k}, total number of labels: {m+k}.')\n",
    "f = np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb835d",
   "metadata": {},
   "source": [
    "# Scenario A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31821c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1113349054557897"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newton(lambda x: k*sigma(x) - m*sigma(-x), x0 = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a38e49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
